{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "327d1f89-4f4e-4a2d-86e0-d8fb6cba6429",
   "metadata": {},
   "source": [
    "## 6. 배포\n",
    "\n",
    "- UI/UX 고려\n",
    "- 프로토 타입 형태 배포: OpenCV 프레임, Gradio, Streamlit \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325c194b-67b8-4844-80fd-8bd79ef3f390",
   "metadata": {},
   "source": [
    "#### 6-1. OpenCV 프레임\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa56e614-017c-44bf-bbf4-b40f0d180e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CPU', 'GPU']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openvino as ov\n",
    "\n",
    "core = ov.Core()\n",
    "options=core.available_devices\n",
    "\n",
    "options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14d8c416-99dc-477e-b7d9-c3918eab6c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino as ov\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the model and prepare the input/output layers\n",
    "core = ov.Core()\n",
    "model = core.read_model(model='models/v3-small_224_1.0_float.xml')\n",
    "compiled_model = core.compile_model(model=model, device_name=\"CPU\")\n",
    "input_layer = compiled_model.input(0)\n",
    "output_layer = compiled_model.output(0)\n",
    "\n",
    "# Load ImageNet classes\n",
    "imagenet_filename = Path('data/imagenet_2012.txt')\n",
    "imagenet_classes = imagenet_filename.read_text().splitlines()\n",
    "imagenet_classes = [\"background\"] + imagenet_classes  # Include the background class\n",
    "\n",
    "def preprocess(image):\n",
    "    # Resize the image to 224x224 and add a batch dimension\n",
    "    input_image = cv2.resize(src=image, dsize=(224, 224))\n",
    "    input_image = np.expand_dims(input_image, axis=0)  # Add batch dimension\n",
    "    return input_image \n",
    "\n",
    "def predict_image(image_path, background_image_path):\n",
    "    # Read the input image\n",
    "    image = cv2.imread(image_path)\n",
    "    input_image = preprocess(image)  # Preprocess the image\n",
    "    result_infer = compiled_model([input_image])[output_layer]  # Perform inference\n",
    "    result_index = np.argmax(result_infer)  # Get the index of the highest score\n",
    "    \n",
    "    # Get the predicted class name\n",
    "    predicted_class = imagenet_classes[result_index]\n",
    "\n",
    "    # Read the background image\n",
    "    bg = cv2.imread(background_image_path)\n",
    "\n",
    "    # Resize the input image to match the proper position of background image\n",
    "    image_h, image_w = image.shape[0], image.shape[1]\n",
    "    new_h = 500\n",
    "    new_w = int((new_h/image_h)*image_w)\n",
    "    image_resize = cv2.resize(image, (new_w, new_h))\n",
    "\n",
    "    \n",
    "    xmax = bg.shape[1] - 200\n",
    "    ymax = bg.shape[0] - 175\n",
    "    xmin = xmax - new_w\n",
    "    ymin = ymax - new_h\n",
    "    \n",
    "    # Overlay the input image on the background image\n",
    "    bg[ymin:ymax, xmin:xmax] = image_resize\n",
    "    \n",
    "    # Overlay the predicted class label on the sample image\n",
    "    cv2.putText(bg, predicted_class, (600, 580), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "\n",
    "    # Display the final combined image\n",
    "    cv2.imshow(\"Sample Image with Prediction on Background\", bg)\n",
    "\n",
    "    # Wait for a key press and close the window\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "sample_image_path = \"./data/coco.jpg\"  # Replace with your actual image file path\n",
    "background_image_path = \"./data/background.jpg\"  # Replace with your actual background image file path\n",
    "\n",
    "predict_image(sample_image_path, background_image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368faac3-a8e5-41d9-8197-825a147688c9",
   "metadata": {},
   "source": [
    "#### 6-2. Gradio\n",
    "https://www.gradio.app/guides/quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa8d153e-4af2-4e06-80ff-18cc418e7460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CPU', 'GPU']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openvino as ov\n",
    "\n",
    "core = ov.Core()\n",
    "options=core.available_devices\n",
    "\n",
    "options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f3a67d6-4c0f-40f2-95d9-eab00ebdd517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openvino as ov\n",
    "import cv2\n",
    "import numpy as np\n",
    "import PIL\n",
    "from pathlib import Path\n",
    "import gradio as gr\n",
    "\n",
    "# Load the model and prepare the input/output layers\n",
    "core = ov.Core()\n",
    "model = core.read_model(model='models/v3-small_224_1.0_float.xml')\n",
    "compiled_model = core.compile_model(model=model, device_name=\"CPU\")\n",
    "input_layer = compiled_model.input(0)\n",
    "output_layer = compiled_model.output(0)\n",
    "\n",
    "# Load ImageNet classes\n",
    "imagenet_filename = Path('data/imagenet_2012.txt')\n",
    "imagenet_classes = imagenet_filename.read_text().splitlines()\n",
    "imagenet_classes = [\"background\"] + imagenet_classes  # Include the background class\n",
    "\n",
    "def preprocess(image):\n",
    "    # Convert the PIL image to a NumPy array and resize to 224x224\n",
    "    image = np.array(image)  # Convert PIL image to numpy array\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # Convert RGB to BGR for OpenCV\n",
    "    input_image = cv2.resize(src=image, dsize=(224, 224))\n",
    "    input_image = np.expand_dims(input_image, axis=0)  # Add batch dimension\n",
    "    return input_image \n",
    "\n",
    "def predict_image(image):\n",
    "    input_image = preprocess(image)  # Preprocess the image\n",
    "    result_infer = compiled_model([input_image])[output_layer]  # Perform inference\n",
    "    result_index = np.argmax(result_infer)  # Get the index of the highest score\n",
    "    \n",
    "    # Get the predicted class name\n",
    "    predicted_class = imagenet_classes[result_index]\n",
    "    return predicted_class  # Return just the predicted class name\n",
    "\n",
    "# Set up the Gradio interface\n",
    "gr.Interface(fn=predict_image,\n",
    "             inputs=gr.Image(type=\"pil\"),\n",
    "             outputs=gr.Textbox(),  # Use Textbox to show the predicted class\n",
    "             examples=[\"./data/coco.jpg\"]).launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33856c0-0464-47c5-a60a-9b8288bbb0b7",
   "metadata": {},
   "source": [
    "#### 6-3. Streamlit\n",
    "https://docs.streamlit.io/get-started/tutorials/create-an-app#create-your-first-app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c59e31fe-6342-4b8f-9831-b6126c2a0ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CPU', 'GPU']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openvino as ov\n",
    "\n",
    "core = ov.Core()\n",
    "options=core.available_devices\n",
    "\n",
    "options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64b37330-aa33-4bc6-91ca-e970543ec9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-01 13:22:07.909 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\kojan\\.conda\\envs\\BrainAI\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import streamlit as st\n",
    "st.title(\"Hello Image Classification :sun_with_face:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b85614-befe-4308-a429-30faf967ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!jupyter nbconvert --to script hello-world-AI-Project-Streamlit.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
